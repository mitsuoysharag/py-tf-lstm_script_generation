{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM - Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2oue2TcbfLx",
        "colab_type": "text"
      },
      "source": [
        "# LSTM - Generación de Texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-viANDVf5lv",
        "colab_type": "text"
      },
      "source": [
        "Importamos TensorFlow y otras librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gdF6XtvF5le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# !pip uninstall tensorflow tensorflow-gpu \n",
        "# !pip install tensorflow tensorflow-gpu\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj9c0wNSf9f_",
        "colab_type": "text"
      },
      "source": [
        "###Leer los datos\n",
        "Cargamos el conjunto de datos por cada script. Y limpiamos los caracteres que no nos interesan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyF6JPZBGPHR",
        "colab_type": "code",
        "outputId": "46935166-5eea-4778-f450-4b7f124625ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "text = ''\n",
        "codes = ['ps1.py', 'ps2.py', 'ps3.py']\n",
        "\n",
        "for code in codes:\n",
        "  text = text + open(code, 'rb').read().decode(encoding='latin-1')\n",
        "  \n",
        "text = text.lower()\n",
        "text = re.sub('#.*\\n', '', text)\n",
        "text = re.sub('\"\"\".*?\"\"\"', '', text, flags=re.DOTALL)\n",
        "text = re.sub(r'(\\n\\s*)+\\n+', '\\n\\n', text, flags=re.DOTALL)\n",
        "text = re.sub(r'\\r', '', text, flags=re.DOTALL)\n",
        "text = text[1:]\n",
        "text = text.replace('\"', \"'\")\n",
        "\n",
        "print('Length of text: {} characters'.format(len(text)))\n",
        "print(text[:500])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 9035 characters\n",
            "import math\n",
            "import random\n",
            "\n",
            "vowels = 'aeiou'\n",
            "consonants = 'bcdfghjklmnpqrstvwxyz'\n",
            "hand_size = 7\n",
            "\n",
            "scrabble_letter_values = {\n",
            "    'a': 1, 'b': 3, 'c': 3, 'd': 2, 'e': 1, 'f': 4, 'g': 2, 'h': 4, 'i': 1, \n",
            "    'j': 8, 'k': 5, 'l': 1, 'm': 3, 'n': 1, 'o': 1, 'p': 3, 'q': 10, 'r': 1,\n",
            "    's': 1, 't': 1, 'u': 1, 'v': 4, 'w': 4, 'x': 8, 'y': 4, 'z': 10\n",
            "}\n",
            "\n",
            "wordlist_filename = 'words.txt'\n",
            "\n",
            "def load_words():\n",
            "\n",
            "    print('loading word list from file...')\n",
            "        infile = open(wordlist_filename, 'r')\n",
            "        wo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I92Q72XgeQF",
        "colab_type": "text"
      },
      "source": [
        "Obtenemos los caracteres únicos de los scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVTuyKHpGvOK",
        "colab_type": "code",
        "outputId": "150a1d57-429a-44bb-f88f-602fb0c8417a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))\n",
        "print(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59 unique characters\n",
            "['\\n', ' ', '!', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', ':', '<', '=', '>', '?', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHY5KVESg8Q1",
        "colab_type": "text"
      },
      "source": [
        "### Vectorizar el texto\n",
        "Antes de entrenar, necesitamos asignar nuestras cadenas a una representación numérica. Creamos dos tablas de búsqueda: una que asigne caracteres a números y otra para números a caracteres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7bhdmsjG7Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAJ5YdSlhhh-",
        "colab_type": "text"
      },
      "source": [
        "Ahora tenemos una representación entera para cada caracter. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJTlaE2tHFbo",
        "colab_type": "code",
        "outputId": "20aee5e2-ebd5-4792-c47d-7bb000b1dbb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '%' :   3,\n",
            "  \"'\" :   4,\n",
            "  '(' :   5,\n",
            "  ')' :   6,\n",
            "  '*' :   7,\n",
            "  '+' :   8,\n",
            "  ',' :   9,\n",
            "  '-' :  10,\n",
            "  '.' :  11,\n",
            "  '/' :  12,\n",
            "  '0' :  13,\n",
            "  '1' :  14,\n",
            "  '2' :  15,\n",
            "  '3' :  16,\n",
            "  '4' :  17,\n",
            "  '5' :  18,\n",
            "  '6' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rF7R8egHgEA",
        "colab_type": "code",
        "outputId": "16da5fc5-652f-411e-a591-ea38ccb4b83c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'import math\\ni' ---- characters mapped to int ---- > [39 43 46 45 48 50  1 43 31 50 38  0 39]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOEelc-1h_ee",
        "colab_type": "text"
      },
      "source": [
        "### Crear ejemplos de entrenamiento y targets.\n",
        "A continuación dividir el texto en secuencias de ejemplo. Cada secuencia de entrada contendrá seq_length caracteres del texto.\n",
        "\n",
        "Para cada secuencia de entrada, los objetivos correspondientes contienen la misma longitud de texto, excepto el desplazamiento de un carácter a la derecha.\n",
        "\n",
        "Entonces rompemos el texto en trozos de seq_length + 1. Por ejemplo, digamos que seq_length es 3 y nuestro texto es \"Hola\". La secuencia de entrada sería \"Hol\" y la secuencia de destino \"ola\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMY6c-_vHmvI",
        "colab_type": "code",
        "outputId": "1851acaf-b5f4-42ee-a44f-e9ed246edb30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(7):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i\n",
            "m\n",
            "p\n",
            "o\n",
            "r\n",
            "t\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H-eaQmfjOoY",
        "colab_type": "text"
      },
      "source": [
        "El método ***batch*** nos permite convertir fácilmente estos caracteres individuales en secuencias del tamaño deseado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSStptdINNp",
        "colab_type": "code",
        "outputId": "411868c6-bf48-4676-e12d-54d70668734b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "print(len(list(sequences)))\n",
        "      \n",
        "for item in sequences.take(3):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89\n",
            "\"import math\\nimport random\\n\\nvowels = 'aeiou'\\nconsonants = 'bcdfghjklmnpqrstvwxyz'\\nhand_size = 7\\n\\nscrab\"\n",
            "\"ble_letter_values = {\\n    'a': 1, 'b': 3, 'c': 3, 'd': 2, 'e': 1, 'f': 4, 'g': 2, 'h': 4, 'i': 1, \\n  \"\n",
            "\"  'j': 8, 'k': 5, 'l': 1, 'm': 3, 'n': 1, 'o': 1, 'p': 3, 'q': 10, 'r': 1,\\n    's': 1, 't': 1, 'u': 1\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf84Rq0Mjs6-",
        "colab_type": "text"
      },
      "source": [
        "Para cada secuencia,  lo duplicamos y movemos para formar el texto de entrada y destino utilizando el método ***map*** para aplicar una función simple a cada lote."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ6GQU4ZJGxT",
        "colab_type": "code",
        "outputId": "60d79a2e-7c9a-43c0-9d92-f4527fe590b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  \"import math\\nimport random\\n\\nvowels = 'aeiou'\\nconsonants = 'bcdfghjklmnpqrstvwxyz'\\nhand_size = 7\\n\\nscra\"\n",
            "Target data: \"mport math\\nimport random\\n\\nvowels = 'aeiou'\\nconsonants = 'bcdfghjklmnpqrstvwxyz'\\nhand_size = 7\\n\\nscrab\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3vXRdpFkSsA",
        "colab_type": "text"
      },
      "source": [
        "Cada índice de estos vectores se procesa como un paso de tiempo. Para la entrada en el paso de tiempo 0, el modelo recibe el índice para \"i\" y trata de predecir el índice para \"m\" como el siguiente carácter. En el siguiente paso de tiempo, hace lo mismo pero el RNN considera el contexto del paso anterior además del carácter de entrada actual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyb-FN6NJYCK",
        "colab_type": "code",
        "outputId": "a685a7f7-6486-40b4-b767-db451132650e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[0:5], target_example[0:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 39 ('i')\n",
            "  expected output: 43 ('m')\n",
            "Step    1\n",
            "  input: 43 ('m')\n",
            "  expected output: 46 ('p')\n",
            "Step    2\n",
            "  input: 46 ('p')\n",
            "  expected output: 45 ('o')\n",
            "Step    3\n",
            "  input: 45 ('o')\n",
            "  expected output: 48 ('r')\n",
            "Step    4\n",
            "  input: 48 ('r')\n",
            "  expected output: 50 ('t')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpU-qJHKks3V",
        "colab_type": "text"
      },
      "source": [
        "### Crear lotes de entrenamiento\n",
        "Utilizamos ***tf.data*** para dividir el texto en secuencias manejables. Pero antes de introducir estos datos en el modelo, debemos barajar los datos y empaquetarlos en lotes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5TJZOIdJolr",
        "colab_type": "code",
        "outputId": "e942e9c8-4cf1-4826-e3e2-840626a8e159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "steps_per_epoch = examples_per_epoch\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((16, 100), (16, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKNNOpbvlN7k",
        "colab_type": "text"
      },
      "source": [
        "### Construir el modelo\n",
        "Utilizamos tf.keras.Sequential para definir el modelo. Para este ejemplo simple se utilizan tres capas para definir nuestro modelo:\n",
        "\n",
        "- **tf.keras.layers.Embedding:** La capa de entrada. Una tabla de búsqueda entrenable que asignará los números de cada carácter a un vector con dimensiones - embedding_dim.\n",
        "- **tf.keras.layers.CuDNNLSTM:** Un tipo de RNN con unidades de tamaño = rnn_units.\n",
        "- **Tf.keras.layers.Dense:** La capa de salida, con salidas vocab_size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG5ZHqKYKRg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1mvqayDl42O",
        "colab_type": "text"
      },
      "source": [
        "A continuación definimos una función para construir el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSdvJfhbKfUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(\n",
        "        vocab_size, \n",
        "        embedding_dim, \n",
        "        batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.CuDNNLSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwflqX2oLuXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size=len(vocab), \n",
        "  embedding_dim=embedding_dim, \n",
        "  rnn_units=rnn_units, \n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICOgFWsZrwWa",
        "colab_type": "text"
      },
      "source": [
        "Para cada carácter, el modelo busca la incrustación (embedding), ejecuta LSTM en un paso de tiempo con la incrustación como entrada y aplica la capa densa para predecir la probabilidad del siguiente carácter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOqYqUFisHdD",
        "colab_type": "text"
      },
      "source": [
        "### Prueba el modelo\n",
        "Ahora ejecuta el modelo para ver que se comporta como se espera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKIbApHyMIFz",
        "colab_type": "code",
        "outputId": "686cf891-5435-4451-8996-f2f393f180c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 100, 59) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6-GOpQGsWIG",
        "colab_type": "text"
      },
      "source": [
        "En el ejemplo anterior, la longitud de la secuencia de la entrada es 100, pero el modelo se puede ejecutar en entradas de cualquier longitud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy01L9loPTzd",
        "colab_type": "code",
        "outputId": "a164616e-904b-4625-e780-da99fe5518b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (16, None, 256)           15104     \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_3 (CuDNNLSTM)     (16, None, 1024)          5251072   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (16, None, 59)            60475     \n",
            "=================================================================\n",
            "Total params: 5,326,651\n",
            "Trainable params: 5,326,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66lp82C9s0qi",
        "colab_type": "text"
      },
      "source": [
        "Para obtener predicciones reales del modelo necesitamos muestrear la distribución de salida, para obtener índices de caracteres reales. \n",
        "Es importante tomar muestras de esta distribución, ya que tomar el argmax de la distribución puede hacer que el modelo quede atrapado en un bucle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1iLSUdjPUIL",
        "colab_type": "code",
        "outputId": "7d029433-6b07-4499-c7b2-45464955761a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15, 58, 16,  0,  3, 42,  2, 57, 51, 11, 40, 21,  5, 54, 31, 22, 39,\n",
              "       40, 50, 34, 10,  5, 25, 46, 35, 28, 13, 50, 24,  3, 42, 24,  0, 54,\n",
              "        3, 33, 26, 13, 52, 57, 25, 11, 15, 13, 19,  1, 39,  6, 56, 29,  2,\n",
              "       20, 30, 26, 29, 27, 34, 42, 43, 42, 41, 26,  8, 52, 10, 30, 37, 42,\n",
              "       23, 33, 42, 58, 41, 48, 31, 48, 35, 16, 26,  6, 41, 36, 48, 13, 15,\n",
              "        8, 29, 15, 58, 10, 46, 57, 18, 32,  5,  9, 14, 49, 58,  7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqQYH42AwYvh",
        "colab_type": "text"
      },
      "source": [
        "Decodificamos para ver el texto predicho por este modelo sin entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRlazEBKQEGk",
        "colab_type": "code",
        "outputId": "4d49362b-ad9f-4ce9-ddbd-91d50344c181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " ' 0) + 1\\n\\n    for i in range(num_vowels+1, n):    \\n        x = random.choice(consonants)\\n        hand'\n",
            "Next Char Predictions: \n",
            " '2}3\\n%l!{u.j8(xa:ijtd-(>pe\\\\0t=%l=\\nx%c?0v{>.206 i)z]!7_?][dlmlk?+v-_gl<cl}krare3?)kfr02+]2}-p{5b(,1s}*'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngQ8649iwgpG",
        "colab_type": "text"
      },
      "source": [
        "### Entrenar a la modelo\n",
        "En este punto, el problema se puede tratar como un problema de clasificación. Dado el estado RNN anterior y la entrada en este paso de tiempo, predice la clase del siguiente carácter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raJ8bNePwpGt",
        "colab_type": "text"
      },
      "source": [
        "### Definir un optimizador, y una función de pérdida\n",
        "La función de pérdida estándar tf.keras.losses.sparse_categorical_crossentropy funciona en este caso porque se aplica en la última dimensión de las predicciones.\n",
        "\n",
        "Debido a que nuestro modelo devuelve logits (el vector de predicciones sin procesar), debemos establecer el distintivo from_logits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtoXOEHoQQzs",
        "colab_type": "code",
        "outputId": "2feed1bb-c5b5-44a4-f3d8-9e7b9b3678f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
        "print(\"loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (16, 100, 59)  # (batch_size, sequence_length, vocab_size)\n",
            "loss:       4.0763707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KxfJaon6i1v",
        "colab_type": "text"
      },
      "source": [
        "Configuramos el procedimiento de capacitación utilizando el método ***tf.keras.Model.compile***. Usaremos tf.train.AdamOptimizer con los argumentos predeterminados y la función de pérdida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G5EiqvXQ6Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = tf.train.AdamOptimizer(),loss = loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGVvtlre6tFm",
        "colab_type": "text"
      },
      "source": [
        "### Configurar puntos de control\n",
        "Usamos ***tf.keras.callbacks.ModelCheckpoint*** para asegurarnos de que los puntos de control se guardan durante el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyuqss6qRA73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB3RNqHJ65ve",
        "colab_type": "text"
      },
      "source": [
        "### Ejecutar el entrenamiento\n",
        "Usamos 5 épocas para entrenar el modelo. En Colab, establecemos el tiempo de ejecución en GPU para un entrenamiento más rápido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Hde4DyREN-",
        "colab_type": "code",
        "outputId": "5782814a-1b80-48ee-eb1c-20b796b4dd6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "EPOCHS = 3\n",
        "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "9035/9035 [==============================] - 340s 38ms/step - loss: 0.0889\n",
            "Epoch 2/5\n",
            "9035/9035 [==============================] - 341s 38ms/step - loss: 0.0238\n",
            "Epoch 3/5\n",
            "9035/9035 [==============================] - 341s 38ms/step - loss: 0.0227\n",
            "Epoch 4/5\n",
            " 270/9035 [..............................] - ETA: 5:32 - loss: 0.0207"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-eec37d556f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Case 3: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \"\"\"\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2104\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-NWPwlx7K6G",
        "colab_type": "text"
      },
      "source": [
        "### Generar texto\n",
        "Restauramos el último punto de control.\n",
        "\n",
        "Para mantener este paso de predicción simple, usamos un tamaño de lote de 1.\n",
        "\n",
        "Debido a la forma en que el estado RNN se pasa de un paso de tiempo a otro, el modelo solo acepta un tamaño de lote fijo una vez construido.\n",
        "\n",
        "Para ejecutar el modelo con un tamaño de lote diferente, necesitamos reconstruir el modelo y restaurar los pesos desde el punto de control."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqJnQW9GWE0L",
        "colab_type": "code",
        "outputId": "4532ff3a-8f16-445e-e56e-5b1703674a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (1, None, 256)            15104     \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_4 (CuDNNLSTM)     (1, None, 1024)           5251072   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (1, None, 59)             60475     \n",
            "=================================================================\n",
            "Total params: 5,326,651\n",
            "Trainable params: 5,326,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGyEdA0R81YC",
        "colab_type": "text"
      },
      "source": [
        "### El bucle de predicción\n",
        "El siguiente bloque de código genera el texto:\n",
        "\n",
        "- Comienza seleccionando una cadena de inicio, inicializando el estado RNN y configurando la cantidad de caracteres que se generarán.\n",
        "\n",
        "- Obtenga la distribución de predicción del siguiente carácter utilizando la cadena de inicio y el estado RNN.\n",
        "\n",
        "- Luego, use una distribución categórica para calcular el índice del carácter predicho. Utilice este carácter predicho como nuestra próxima entrada al modelo.\n",
        "\n",
        "- El estado RNN devuelto por el modelo se retroalimenta en el modelo para que ahora tenga más contexto, en lugar de una sola palabra. Después de predecir la siguiente palabra, los estados RNN modificados se incorporan nuevamente al modelo, que es la forma en que aprende a medida que obtiene más contexto de las palabras predichas previamente.\n",
        "\n",
        "- Para generar texto, la salida del modelo se retroalimenta a la entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jLTKUmERQV_",
        "colab_type": "code",
        "outputId": "dee9c74b-2b20-4eee-bd10-5d399faf0108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generate = 1030\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      \n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n",
        "\n",
        "print(generate_text(model, start_string=\"for \"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for x in sequence:\n",
            "        freq[x] = freq.get(x,0) + 1\n",
            "    for i in range(1, 37, 1):\n",
            "        component1 += scrabble_letter_values.get(i,0)\n",
            "\n",
            "    component2 = max(7*word_length-3*(n-word_le_surrent_savings += (current_savings*r/12 \n",
            "                            + portion_saved*(local_annual_sand[i]\n",
            "\n",
            "    return sum_\n",
            "\n",
            "def play_hand(hand, word_list):\n",
            "\n",
            "    new_hand = hand.copy()\n",
            "    total_pointsavings(high) < portion_down_payment:\n",
            "        print('it is not possible to pay the down payment in the cost of your dream home: '))\n",
            "semi_annual_raise = float(input('insert the semi-annual raise, as decer = input('would you like to replay the hand? ')\n",
            "            if answer in {'no', 'no', 'no'}:\n",
            "           for x in word_list)\n",
            "\n",
            "def calculate_handlen(hand):\n",
            "\n",
            "    sum_ = 0\n",
            "    for i in hand:\n",
            "        sum_ += he cost of your dream home: '))\n",
            "semi_annual_raise = float(input('insert the semi-annual raise, as decer = input('would you like to replay the hand? ')\n",
            "            if answer in {'no', 'no', 'no'}:\n",
            "                    break\n",
            "                e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u87q9WzJ909P",
        "colab_type": "text"
      },
      "source": [
        "### Referencias\n",
        "- https://www.tensorflow.org/tutorials/sequences/text_generation"
      ]
    }
  ]
}
